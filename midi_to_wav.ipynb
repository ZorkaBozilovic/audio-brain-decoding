{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba9a27ea-2128-4536-989a-1ddc12a5c197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Converting audio1.mid...\n",
      "✓ Saved 1.wav (158.04s, max amp: 0.10)\n",
      "→ Converting audio2.mid...\n",
      "✓ Saved 2.wav (153.10s, max amp: 0.10)\n",
      "→ Converting audio3.mid...\n",
      "✓ Saved 3.wav (119.29s, max amp: 0.10)\n",
      "→ Converting audio4.mid...\n",
      "✓ Saved 4.wav (134.50s, max amp: 0.10)\n",
      "→ Converting audio5.mid...\n",
      "✓ Saved 5.wav (164.73s, max amp: 0.10)\n",
      "→ Converting audio6.mid...\n",
      "✓ Saved 6.wav (198.31s, max amp: 0.10)\n",
      "→ Converting audio7.mid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mtrf/lib/python3.10/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 7.wav (172.17s, max amp: 0.10)\n",
      "→ Converting audio8.mid...\n",
      "✓ Saved 8.wav (181.21s, max amp: 0.10)\n",
      "→ Converting audio9.mid...\n",
      "✓ Saved 9.wav (133.17s, max amp: 0.10)\n",
      "→ Converting audio10.mid...\n",
      "✓ Saved 10.wav (177.10s, max amp: 0.10)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 6\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import eelbrain\n",
    "from scipy.io import loadmat\n",
    "import eelbrain.datasets._alice\n",
    "from matplotlib import pyplot\n",
    "import mne\n",
    "from mne.channels import make_dig_montage\n",
    "import numpy as np\n",
    "from mne import find_events\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Define the dataset root; this will use ~/Data/Alice, replace it with the\n",
    "# proper path if you downloaded the dataset in a different location\n",
    "DATA_ROOT = Path('FYP/music data')\n",
    "\n",
    "# Define some paths that will be used throughout\n",
    "STIMULUS_DIR = DATA_ROOT / 'diliBach_midi_4dryad'\n",
    "EEG_DIR = DATA_ROOT / 'diliBach_4dryad_CND'\n",
    "\n",
    "# Load one subject's raw EEG file\n",
    "SUBJECT = 'Sub1'\n",
    "LOW_FREQUENCY = 0.5\n",
    "HIGH_FREQUENCY = 20\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pretty_midi\n",
    "import soundfile as sf  # Native WAV writing\n",
    "\n",
    "SOUNDFONT_PATH = Path(\"path/to/your/soundfont.sf2\")  # Optional but better results\n",
    "\n",
    "def convert_midi_to_wav(fs=44100, gain=0.1, trim_thresh=1e-4):\n",
    "    \"\"\"Convert MIDI to WAV, normalize amplitude, and trim leading silence.\"\"\"\n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        midi_file = STIMULUS_DIR / f'audio{i}.mid'\n",
    "        wav_file = STIMULUS_DIR / f'{i}.wav'\n",
    "        \n",
    "        if not midi_file.exists():\n",
    "            print(f\"✗ {midi_file.name} not found\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"→ Converting {midi_file.name}...\")\n",
    "            midi = pretty_midi.PrettyMIDI(str(midi_file))\n",
    "\n",
    "            # Render audio\n",
    "            if SOUNDFONT_PATH.exists():\n",
    "                audio = midi.fluidsynth(fs=fs, sf2_path=str(SOUNDFONT_PATH))\n",
    "            else:\n",
    "                audio = midi.synthesize(fs=fs)\n",
    "\n",
    "            # Trim leading silence (based on amplitude threshold)\n",
    "            abs_audio = np.abs(audio)\n",
    "            nonzero_idx = np.where(abs_audio > trim_thresh)[0]\n",
    "            if len(nonzero_idx) > 0:\n",
    "                start_idx = nonzero_idx[0]\n",
    "                audio = audio[start_idx:]\n",
    "            else:\n",
    "                print(f\"⚠ No audible content in {midi_file.name}\")\n",
    "                continue\n",
    "\n",
    "            # Normalize amplitude\n",
    "            max_amp = np.max(np.abs(audio))\n",
    "            if max_amp > 0:\n",
    "                audio = audio * (gain / max_amp)\n",
    "\n",
    "            # Save WAV\n",
    "            sf.write(str(wav_file), audio, fs)\n",
    "            duration = len(audio) / fs\n",
    "            print(f\"✓ Saved {wav_file.name} ({duration:.2f}s, max amp: {gain:.2f})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to convert {midi_file.name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert MIDI files to WAV\n",
    "convert_midi_to_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2c99f-3bed-40af-9942-a9e8b4ded435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
